{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab8_DQN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/oleges1/PML/blob/master/lab8_DQN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ETykzMWVqQ-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02d9e05e-fd3e-4355-85ab-be1f6c9043fa"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Activation, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fZMxaIFn0V_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Our enviroment and some constants"
      ]
    },
    {
      "metadata": {
        "id": "zXCVPG9AdTag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "531b3b10-85c2-4bc1-8417-00d37c03db84"
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('Skiing-v0')\n",
        "state_size = (1, 125, 80, 3)\n",
        "action_size = env.action_space.n\n",
        "input_shape = (125, 80, 3)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
            "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Xdw0_BV0N8R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional network for DQN"
      ]
    },
    {
      "metadata": {
        "id": "ZKvytRPWozhr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1111
        },
        "outputId": "f12cfb1e-6c48-4a43-b21a-eeef1c82f6f2"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.utils import conv_utils\n",
        "from keras.engine import InputSpec\n",
        "from keras.engine import Layer\n",
        "from tensorflow import image as tfi\n",
        "\n",
        "class ResizeImages(Layer):\n",
        "    \"\"\"Resize Images to a specified size\n",
        "\n",
        "    # Arguments\n",
        "        output_size: Size of output layer width and height\n",
        "        data_format: A string,\n",
        "            one of `channels_last` (default) or `channels_first`.\n",
        "            The ordering of the dimensions in the inputs.\n",
        "            `channels_last` corresponds to inputs with shape\n",
        "            `(batch, height, width, channels)` while `channels_first`\n",
        "            corresponds to inputs with shape\n",
        "            `(batch, channels, height, width)`.\n",
        "            It defaults to the `image_data_format` value found in your\n",
        "            Keras config file at `~/.keras/keras.json`.\n",
        "            If you never set it, then it will be \"channels_last\".\n",
        "\n",
        "    # Input shape\n",
        "        - If `data_format='channels_last'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, rows, cols, channels)`\n",
        "        - If `data_format='channels_first'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, channels, rows, cols)`\n",
        "\n",
        "    # Output shape\n",
        "        - If `data_format='channels_last'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, pooled_rows, pooled_cols, channels)`\n",
        "        - If `data_format='channels_first'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, channels, pooled_rows, pooled_cols)`\n",
        "    \"\"\"\n",
        "    def __init__(self, output_dim=(1, 1), data_format=None, **kwargs):\n",
        "        super(ResizeImages, self).__init__(**kwargs)\n",
        "        data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.output_dim = conv_utils.normalize_tuple(output_dim, 2, 'output_dim')\n",
        "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            return (input_shape[0], input_shape[1], self.output_dim[0], self.output_dim[1])\n",
        "        elif self.data_format == 'channels_last':\n",
        "            return (input_shape[0], self.output_dim[0], self.output_dim[1], input_shape[3])\n",
        "\n",
        "    def _resize_fun(self, inputs, data_format):\n",
        "        try:\n",
        "            assert keras.backend.backend() == 'tensorflow'\n",
        "            assert self.data_format == 'channels_last'\n",
        "        except AssertionError:\n",
        "            print (\"Only tensorflow backend is supported for the resize layer and accordingly 'channels_last' ordering\")\n",
        "        output = tfi.resize_images(inputs, self.output_dim)\n",
        "        return output\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = self._resize_fun(inputs=inputs, data_format=self.data_format)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'output_dim': self.output_dim,\n",
        "                  'padding': self.padding,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(ResizeImages, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(ResizeImages((64, 42), input_shape=input_shape))\n",
        "model.add(Conv2D(16, (10, 10), padding='valid', input_shape=input_shape))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Conv2D(16, (5, 5), padding='same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size = (4, 4), padding = 'same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "\n",
        "model.add(Conv2D(32, (6, 6), padding='valid'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size = (3, 3), padding = 'same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "    \n",
        "model.add(Conv2D(64, (4, 4), padding='same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Conv2D(64, (2, 2), padding='valid'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), padding = 'same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(BatchNormalization(axis = 1))\n",
        "\n",
        "#model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "#model.add(LeakyReLU())\n",
        "#model.add(Conv2D(256, (2, 2), padding='valid'))\n",
        "#model.add(LeakyReLU())\n",
        "#model.add(MaxPooling2D(pool_size = (2, 2), padding = 'same'))\n",
        "#model.add(LeakyReLU())\n",
        "#model.add(BatchNormalization(axis = 3))\n",
        "\n",
        "    \n",
        "#model.add(Conv2D(1, (1, 1), padding='same'))\n",
        "#model.add(LeakyReLU())\n",
        "#model.add(Flatten())\n",
        "\n",
        "model.add(LeakyReLU())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dense(action_size))\n",
        "    \n",
        "model.add(Activation('linear'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "model.compile(loss='mse', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()\n",
        "graph = tf.get_default_graph()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 116, 71, 16)       4816      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 116, 71, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 116, 71, 16)       6416      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 116, 71, 16)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 29, 18, 16)        0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 29, 18, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 29, 18, 16)        116       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 13, 32)        18464     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 24, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 13, 32)        9248      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 24, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 8, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 5, 32)          32        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 5, 64)          32832     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 8, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 4, 64)          16448     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 7, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 4, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4, 2, 64)          16        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 4, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               51300     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 303       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 139,991\n",
            "Trainable params: 139,909\n",
            "Non-trainable params: 82\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q2Ix-i4uzj0L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Agent class\n",
        "\n",
        "Prepare a special class for deep Q-learning\n",
        "It has a state storage for 10000 states, network and some special functions for remembering states and updating network."
      ]
    },
    {
      "metadata": {
        "id": "cOSIAc9Ccn41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size, model, graph, epsilon_decay = 0.999):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        #self.memory = deque(maxlen=2000)\n",
        "        self.iters = 0\n",
        "        self.memory_size = 10000\n",
        "        self.memory_state = np.zeros((self.memory_size, state_size[0], state_size[1], state_size[2], state_size[3]))\n",
        "        self.memory_action = np.zeros((self.memory_size))\n",
        "        self.memory_reward = np.zeros((self.memory_size))\n",
        "        self.memory_next_state = np.zeros((self.memory_size, state_size[0], state_size[1], state_size[2], state_size[3]))\n",
        "        self.memory_done = np.zeros((self.memory_size))\n",
        "        self.size = 0\n",
        "        \n",
        "        self.fill = 0\n",
        "        \n",
        "        self.gamma = 0.97    # discount rate\n",
        "        self.epsilon = 1.0  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.learning_rate = 0.001\n",
        "        self.model = model\n",
        "        self.graph = graph\n",
        "    \n",
        "    def last_state_remem(self, reward, lens):\n",
        "        temp_iter = self.iters\n",
        "        end_iter = (self.iters - lens + self.memory_size) % self.memory_size\n",
        "        while (temp_iter != end_iter):\n",
        "          self.memory_reward[temp_iter] += reward\n",
        "          reward *= 0.99\n",
        "          self.memory_done[temp_iter] = 1\n",
        "          temp_iter -= 1\n",
        "          if (temp_iter < 0):\n",
        "            temp_iter = self.memory_size - 9\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        #print(self.memory_state.shape, state.shape)\n",
        "        self.memory_state[self.iters] = state\n",
        "        self.memory_action[self.iters] = action\n",
        "        self.memory_reward[self.iters] = reward\n",
        "        self.memory_next_state[self.iters] = next_state\n",
        "        self.memory_done[self.iters] = 0\n",
        "        self.iters += 1\n",
        "        self.size += 1\n",
        "        if (self.iters + 10 >= self.memory_size):\n",
        "          self.iters = 0\n",
        "          self.fill = 1\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        with self.graph.as_default():\n",
        "          act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values)  # returns action\n",
        "\n",
        "    def replay(self, batch_size, indx = None):\n",
        "      with self.graph.as_default():\n",
        "        if type(indx) == None:\n",
        "          indx = self.memory_done.nonzero()[0]\n",
        "        if (self.fill):\n",
        "          filteration = np.random.choice(indx, batch_size)\n",
        "        else:\n",
        "          filteration = np.random.choice(self.iters, batch_size)\n",
        "        for i in filteration:\n",
        "        # for state, action, reward, next_state, done in self.memory:\n",
        "            #print(state.shape, action, reward, next_state.shape, done, state_size)\n",
        "     \n",
        "            #print(np.amax(self.model.predict(next_state.reshape(state_size))))\n",
        "            \n",
        "            state = self.memory_state[i]\n",
        "            action = self.memory_action[i]\n",
        "            reward = self.memory_reward[i]\n",
        "            next_state = self.memory_next_state[i]\n",
        "            \n",
        "            target = reward + self.gamma * np.amax(self.model.predict(state))\n",
        "            \n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][int(action)] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "        #if (len(self.memory) > 2000):\n",
        "        #  self.memory = self.memory[batch_size:]\n",
        "        #self.memory = []\n",
        "        self.size = 0\n",
        "\n",
        "    def load(self, name):\n",
        "      with self.graph.as_default():\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "      with self.graph.as_default():\n",
        "        self.model.save_weights(name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1X-fb7YS0ker",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need too resize input image, so let's use:"
      ]
    },
    {
      "metadata": {
        "id": "X2dwd5gi8s1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "def prepare_state(img):\n",
        "  return resize(img, (125, 80), mode = 'reflect')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aJ4sLi7E0rDz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usage of this class"
      ]
    },
    {
      "metadata": {
        "id": "ledDkLRIQqkW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "from tqdm import tqdm\n",
        "agent = DQNAgent(state_size, action_size, model, graph, epsilon_decay = 0.77)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xD5RMeLopFk6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Learning part\n",
        "\n",
        "Scheme of learning.\n",
        "* Store some initial parties and fill a half of our state storage.\n",
        "* After each game update network on 1300 states randomly sampled from storage."
      ]
    },
    {
      "metadata": {
        "id": "3HR6WgMU1iaw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def learning(agent, batch_size = 1, episodes = 15, verbose = 0):\n",
        "  done = False\n",
        "  for e in range(episodes):\n",
        "      state = env.reset()\n",
        "      state = np.reshape(prepare_state(state), state_size)\n",
        "      done = 0\n",
        "      start = time()\n",
        "      score = 0.0\n",
        "      for times in range(2500):\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        reward = reward if not done else 8000\n",
        "        score += reward\n",
        "        next_state = np.reshape(prepare_state(next_state), state_size)\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        if done:\n",
        "          print(\"done: {}, episode: {}/{}, score: {}, e: {:.2}, time:{} \"\n",
        "                      .format(done, e, episodes, score, agent.epsilon, time() - start))\n",
        "          break\n",
        "        if (verbose and times % 100 == 0):\n",
        "          print(\"done: {}, episode: {}/{}, score: {}, e: {:.2}, time:{} \"\n",
        "                      .format(done, e, episodes, score, agent.epsilon, time() - start))\n",
        "      agent.last_state_remem(reward, times)\n",
        "      if (agent.iters > 4000 or agent.fill):\n",
        "          indx = agent.memory_done.nonzero()[0]\n",
        "          agent.replay(batch_size, indx = indx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YvsXaE9Voi79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1563
        },
        "outputId": "81a1e700-57ae-4511-a565-4e656db74912"
      },
      "cell_type": "code",
      "source": [
        "#agent.epsilon = 0.08\n",
        "agent.epsilon_decay = 0.97\n",
        "learning(agent, verbose = 1, episodes = 6)\n",
        "print(agent.epsilon)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done: False, episode: 0/6, score: -3.0, e: 0.056, time:0.008185625076293945 \n",
            "done: False, episode: 0/6, score: -503.0, e: 0.056, time:0.7582042217254639 \n",
            "done: False, episode: 0/6, score: -997.0, e: 0.056, time:1.4607675075531006 \n",
            "done: False, episode: 0/6, score: -1499.0, e: 0.056, time:2.184581995010376 \n",
            "done: False, episode: 0/6, score: -2002.0, e: 0.056, time:3.0184271335601807 \n",
            "done: False, episode: 0/6, score: -2496.0, e: 0.056, time:3.8930866718292236 \n",
            "done: False, episode: 0/6, score: -2980.0, e: 0.056, time:4.739461898803711 \n",
            "done: False, episode: 0/6, score: -3490.0, e: 0.056, time:5.5728466510772705 \n",
            "done: False, episode: 0/6, score: -3979.0, e: 0.056, time:6.419341802597046 \n",
            "done: False, episode: 0/6, score: -4456.0, e: 0.056, time:7.248562812805176 \n",
            "done: False, episode: 0/6, score: -4947.0, e: 0.056, time:8.10669493675232 \n",
            "done: False, episode: 0/6, score: -5437.0, e: 0.056, time:8.95321774482727 \n",
            "done: True, episode: 0/6, score: 2405.0, e: 0.056, time:9.218910932540894 \n",
            "done: False, episode: 1/6, score: -5.0, e: 0.054, time:0.00781702995300293 \n",
            "done: False, episode: 1/6, score: -521.0, e: 0.054, time:0.8935298919677734 \n",
            "done: False, episode: 1/6, score: -993.0, e: 0.054, time:1.7659995555877686 \n",
            "done: False, episode: 1/6, score: -1463.0, e: 0.054, time:2.6020286083221436 \n",
            "done: False, episode: 1/6, score: -1975.0, e: 0.054, time:3.4368841648101807 \n",
            "done: False, episode: 1/6, score: -2479.0, e: 0.054, time:4.268167734146118 \n",
            "done: False, episode: 1/6, score: -2960.0, e: 0.054, time:5.141427755355835 \n",
            "done: False, episode: 1/6, score: -3425.0, e: 0.054, time:5.963589191436768 \n",
            "done: False, episode: 1/6, score: -3916.0, e: 0.054, time:6.808533191680908 \n",
            "done: False, episode: 1/6, score: -4408.0, e: 0.054, time:7.6342668533325195 \n",
            "done: False, episode: 1/6, score: -4899.0, e: 0.054, time:8.433567762374878 \n",
            "done: False, episode: 1/6, score: -5390.0, e: 0.054, time:9.276204109191895 \n",
            "done: False, episode: 1/6, score: -5877.0, e: 0.054, time:10.11536431312561 \n",
            "done: False, episode: 1/6, score: -6377.0, e: 0.054, time:10.93056583404541 \n",
            "done: False, episode: 1/6, score: -6878.0, e: 0.054, time:11.73592495918274 \n",
            "done: False, episode: 1/6, score: -7375.0, e: 0.054, time:12.566753387451172 \n",
            "done: False, episode: 1/6, score: -7864.0, e: 0.054, time:13.384674549102783 \n",
            "done: False, episode: 1/6, score: -8374.0, e: 0.054, time:14.257903575897217 \n",
            "done: False, episode: 1/6, score: -8886.0, e: 0.054, time:15.088340044021606 \n",
            "done: True, episode: 1/6, score: -934.0, e: 0.054, time:15.173988580703735 \n",
            "done: False, episode: 2/6, score: -7.0, e: 0.052, time:0.008959293365478516 \n",
            "done: False, episode: 2/6, score: -481.0, e: 0.052, time:0.8335258960723877 \n",
            "done: False, episode: 2/6, score: -992.0, e: 0.052, time:1.7070722579956055 \n",
            "done: False, episode: 2/6, score: -1474.0, e: 0.052, time:2.5511832237243652 \n",
            "done: False, episode: 2/6, score: -1984.0, e: 0.052, time:3.3981192111968994 \n",
            "done: False, episode: 2/6, score: -2481.0, e: 0.052, time:4.23346471786499 \n",
            "done: False, episode: 2/6, score: -2962.0, e: 0.052, time:5.068805694580078 \n",
            "done: False, episode: 2/6, score: -3463.0, e: 0.052, time:5.896696329116821 \n",
            "done: False, episode: 2/6, score: -3980.0, e: 0.052, time:6.7165632247924805 \n",
            "done: False, episode: 2/6, score: -4480.0, e: 0.052, time:7.540038108825684 \n",
            "done: True, episode: 2/6, score: 3116.0, e: 0.052, time:8.213617324829102 \n",
            "done: False, episode: 3/6, score: -3.0, e: 0.051, time:0.007999181747436523 \n",
            "done: False, episode: 3/6, score: -489.0, e: 0.051, time:0.8538076877593994 \n",
            "done: False, episode: 3/6, score: -1015.0, e: 0.051, time:1.6883690357208252 \n",
            "done: False, episode: 3/6, score: -1498.0, e: 0.051, time:2.522536516189575 \n",
            "done: False, episode: 3/6, score: -1992.0, e: 0.051, time:3.3524794578552246 \n",
            "done: False, episode: 3/6, score: -2498.0, e: 0.051, time:4.180941343307495 \n",
            "done: False, episode: 3/6, score: -3002.0, e: 0.051, time:5.013709783554077 \n",
            "done: False, episode: 3/6, score: -3506.0, e: 0.051, time:5.844342470169067 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "done: False, episode: 3/6, score: -4020.0, e: 0.051, time:6.667902946472168 \n",
            "done: False, episode: 3/6, score: -4555.0, e: 0.051, time:7.524429798126221 \n",
            "done: False, episode: 3/6, score: -5062.0, e: 0.051, time:8.35753059387207 \n",
            "done: False, episode: 3/6, score: -5550.0, e: 0.051, time:9.192582607269287 \n",
            "done: False, episode: 3/6, score: -6034.0, e: 0.051, time:10.034673690795898 \n",
            "done: False, episode: 3/6, score: -6541.0, e: 0.051, time:10.857566833496094 \n",
            "done: False, episode: 3/6, score: -7041.0, e: 0.051, time:11.650041341781616 \n",
            "done: False, episode: 3/6, score: -7540.0, e: 0.051, time:12.4916410446167 \n",
            "done: False, episode: 3/6, score: -8031.0, e: 0.051, time:13.333173990249634 \n",
            "done: False, episode: 3/6, score: -8533.0, e: 0.051, time:14.166411638259888 \n",
            "done: False, episode: 3/6, score: -9016.0, e: 0.051, time:15.024471282958984 \n",
            "done: False, episode: 3/6, score: -9503.0, e: 0.051, time:15.8651762008667 \n",
            "done: False, episode: 3/6, score: -10008.0, e: 0.051, time:16.703890562057495 \n",
            "done: True, episode: 3/6, score: -2197.0, e: 0.051, time:17.059499979019165 \n",
            "done: False, episode: 4/6, score: -7.0, e: 0.049, time:0.009267330169677734 \n",
            "done: False, episode: 4/6, score: -499.0, e: 0.049, time:0.8442490100860596 \n",
            "done: False, episode: 4/6, score: -1025.0, e: 0.049, time:1.6889152526855469 \n",
            "done: False, episode: 4/6, score: -1524.0, e: 0.049, time:2.5355007648468018 \n",
            "done: False, episode: 4/6, score: -2015.0, e: 0.049, time:3.385078191757202 \n",
            "done: False, episode: 4/6, score: -2481.0, e: 0.049, time:4.226318836212158 \n",
            "done: False, episode: 4/6, score: -2999.0, e: 0.049, time:5.079436779022217 \n",
            "done: False, episode: 4/6, score: -3500.0, e: 0.049, time:5.894702672958374 \n",
            "done: False, episode: 4/6, score: -3990.0, e: 0.049, time:6.710172653198242 \n",
            "done: False, episode: 4/6, score: -4490.0, e: 0.049, time:7.534268617630005 \n",
            "done: False, episode: 4/6, score: -4981.0, e: 0.049, time:8.375969171524048 \n",
            "done: True, episode: 4/6, score: 2673.0, e: 0.049, time:8.984834671020508 \n",
            "done: False, episode: 5/6, score: -7.0, e: 0.048, time:0.008960723876953125 \n",
            "done: False, episode: 5/6, score: -514.0, e: 0.048, time:0.8791251182556152 \n",
            "done: False, episode: 5/6, score: -1037.0, e: 0.048, time:1.7412948608398438 \n",
            "done: False, episode: 5/6, score: -1553.0, e: 0.048, time:2.6194279193878174 \n",
            "done: False, episode: 5/6, score: -2060.0, e: 0.048, time:3.4563236236572266 \n",
            "done: False, episode: 5/6, score: -2563.0, e: 0.048, time:4.3082499504089355 \n",
            "done: False, episode: 5/6, score: -3045.0, e: 0.048, time:5.12866735458374 \n",
            "done: False, episode: 5/6, score: -3551.0, e: 0.048, time:5.983503580093384 \n",
            "done: False, episode: 5/6, score: -4047.0, e: 0.048, time:6.809256076812744 \n",
            "done: True, episode: 5/6, score: 3728.0, e: 0.048, time:7.1749067306518555 \n",
            "0.046236101003443254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iLknLv7BqvuJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save result"
      ]
    },
    {
      "metadata": {
        "id": "bC2RX7r0UsV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "agent.save('best.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zKso0I8Pqzg6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Show playing in colab:"
      ]
    },
    {
      "metadata": {
        "id": "5P3x_AU9VN2p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5VpKNW6TQiL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "def show_agent_play(env, agent):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(prepare_state(state), state_size)\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    #plt.title(\"%s | Step: %d %s\" % (env._spec.id,step, info))\n",
        "    plt.axis('off')\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    while done != True:\n",
        "        a = agent.act(state)\n",
        "        state2, reward, done, info = env.step(a)\n",
        "        episode_reward += reward\n",
        "        plt.imshow(env.render(mode='rgb_array'))\n",
        "        #plt.title(\"%s | Step: %d %s\" % (env._spec.id,step, info))\n",
        "        plt.axis('off')\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())\n",
        "        state = np.reshape(prepare_state(state2), state_size)\n",
        "    env.close()\n",
        "    return episode_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ADqyZxPTftT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_agent_play(env, agent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMlOyQz0rBdb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save data"
      ]
    },
    {
      "metadata": {
        "id": "-zJhV8oQWvMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def saver(name):\n",
        "  file_metadata = {\n",
        "    'name': name + '.h5',\n",
        "    'mimeType': 'application/octet-stream'\n",
        "  }\n",
        "  media = MediaFileUpload(name + '.h5', \n",
        "                          mimetype='application/octet-stream',\n",
        "                          resumable=True)\n",
        "  created = drive_service.files().create(body=file_metadata,\n",
        "                                         media_body=media).execute()\n",
        "  print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJ83g9nn08Nj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a82e82f-d653-49f5-89f8-b781139db92e"
      },
      "cell_type": "code",
      "source": [
        "! ls -a"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".   best.h5  .config  .forever\t.ipython  .local  .rnd\t  second.h5\r\n",
            "..  .cache   datalab  gym\t.keras\t  .nv\t  second\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Xw6AgkSXLT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7246229d-2f59-498d-fd25-895a2f740045"
      },
      "cell_type": "code",
      "source": [
        "saver('best')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1ZMR2Zxfz4Zw0jcCU2MQ-AcIZ25ykcX2p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FfS4m8V4rViJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_agent_play(env, agent):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(prepare_state(state), state_size)\n",
        "    env.render(mode='rgb_array')\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    while done != True:\n",
        "        a = agent.act(state)\n",
        "        state2, reward, done, info = env.step(a)\n",
        "        episode_reward += reward\n",
        "        env.render()\n",
        "        state = np.reshape(prepare_state(state2), state_size)\n",
        "    env.close()\n",
        "    return episode_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flG9_O6zrPGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "agent.load('best.h5')\n",
        "agent.epsilon = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9NgazrIprbpK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_agent_play(env, agent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4U5vY4vXrsLx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### About agent playing\n",
        "\n",
        "If `epsilon = 0.0`, agent sky down the slope.\n",
        "If epsilon is bigger you may notice some random actions."
      ]
    }
  ]
}